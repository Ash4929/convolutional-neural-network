# -*- coding: utf-8 -*-
"""CNN on Cifar10 Datasets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_pbRUNs2ZeHm1wz62OUP2fLWAqMK0odw
"""

##CNN

"""First CNN Model

CNN is Regularized version of Multi layer Perceptron

**Multi Layer Perceptron is actually Fully Connected n/w(Each Neuron in a layer is fully connected to each Neuron in other/Next Layer)

This type of model is very prone to OVERFIT.  
That's why CNN is called Regularized version of ANN

Filters:
Numbers of filter can't be exceed to with some numbers, coz More the filter heigher the chance of Overfit
(Count of filter is also called as "Depth" of filter)


Stride Size: It how the Filter of 3*3 or any size) * Kernal to extract the features
Filter is moving ie how many pixel it is skipping, this is known as Stride Size
**Default Stride size is 1


Padding:
After actual data, 0 is padded around the actual data.

1. Padding added (If Required)
2. Filter goes along(move 1/2..(depends on Stride) Steps all around 
3. In each Move Filter get multiplied with Kernal and o/p is calculated
4. That O/P is called "Features" of the image



Max Pooling:
It pulls the maximum value from a range of data



Flattening and Dense Layer:
Flatten layer transform 2-D data into vector, then only it van be feed to Fully connected NN classifier.
T
"""

pip install tensorflow-gpu==2.0

pip install mlxtend==0.17.0

import tensorflow as tf

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Flatten, Dense , Conv2D, MaxPool2D, Dropout

tf.__version__

import numpy as np
import matplotlib.pyplot as plt

"""Now we will download the data(It is available is Kers Datasets)"""

from tensorflow.keras.datasets import cifar10

"""Data comes in form of Tuple, Train and Test"""

(x_train, y_train), (x_test, y_test)= cifar10.load_data()

"""We also need Class Name for this data(as it would not be present in downloaded data) :: We got these names from dataset description in Kaggle"""

classes_names= ['airplane','automobile','bird','cat','deer','dog','horse','ship', 'truck']

"""Let's understand the data"""

x_train.shape

y_train.shape

x_test.shape

'max value'
x_train.max()

"""But in NN we prefer the number should be closer to 1, that's why we do Standarization(converting all number between 0 to 1)

So, we can convert by dividing each number with max value(ie 255)
"""

x_train=x_train/255
x_test=x_test/255

x_train.max()

'Now we will check Max value, it should be 1 NOT 225(Means Our Standarization step worked Propeely)'
x_train.max()

'Shape of data'
x_train.shape

"""Means there are 50,000 images, each of 32*32 poxel and it is 3-D images

3-D means , R-G-B is Color Image

Let's see some images
"""

plt.imshow(x_test[0])

"""Lets see what is this?"""

y_test[0]

"""It is cat , coz (we saw from googlr the image @ 3rd index position is Cat.

[Link: ](https://www.cs.toronto.edu/~kriz/cifar.html)

## **Lets Start our CNN Model**
"""

'Covolutional Layer'
model= Sequential()
model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=[32,32,3]))
model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))

model.add(MaxPool2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Dropout(0.5))

'Flattening Layer'
model.add(Flatten())

'Dense Layer'
model.add(Dense(units=128, activation='relu'))

'Output Layer'
model.add(Dense(units=10, activation='softmax'))

"""Filter: No of usage of filter depends on usage and hit and trial 

Kernal Size= 3*3  means (3*3 matrix Kernal)

Padding: Putting 0 aroud the data matrix
         *Same: It keeps the same dimention on which we applying filter
         *valid: It reduces the dimention of data on which we applying filter

Dropout: Dropout is used to dropout given % of data while calculation next step
         *It is used to avoid Overfitting of Model


Softmax: It is used when there are >2 O/P in Classification Model
"""

model.summary()

'Compiling the Model'

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])

'Fitting Model'
'Saving result for view other details* for each Epoch, [* loss, accuracy  all to plot lerning curve]'
history=model.fit(x_train, y_train, batch_size=10, epochs=10, verbose=1, validation_data=(x_test, y_test))

"""Above, we can see Accuracy: 81% and Validation Accuracy:70%                
(which shows an example of overfitting of model)

**We can see that, from 5th epoch the problem of overfitting is  getting started
"""

'Plotting Learning Plot for Train and Test Accuracy'
epoch_range=range(1,11)
plt.plot(epoch_range, history.history['sparse_categorical_accuracy'])
plt.plot(epoch_range, history.history['val_sparse_categorical_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.show()

#Plotting Learning Plot for Train and Test Loss
epoch_range=range(1,11)
plt.plot(epoch_range, history.history['loss'])
plt.plot(epoch_range, history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.show()

"""Accuracy:
Train Accuracy is increasing but for validation Accuracy is NOT Increasing in same manner.(We can see that from 4th Epoch Validatio Accuracy went down)

Loss:
Train Loss is Decreasing but for validation Loss is NOT Decreasing in same manner.(We can see that from 4th Epoch Validatio Loss went UP)

** Summary: From 4th Epoch result is getting bad
"""

'We can enhamce the Model Result, by adding more Layers. This way we can RE-TRAIN the Model(Will Do Later)'

'Plotting Confussion Matrix'

from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix

#First predict for test data
y_pred= model.predict_classes(x_test)

'Lets compare roughly'

y_test

y_pred

#Confussion Matrix(Coventional Way: Using SK Learn Lib)
confusion_matrix(y_test, y_pred)

'This way is not very Intutive, so will use MLEXTEND Library'
mat=confusion_matrix(y_test, y_pred)
#plot_confusion_matrix(mat, figsize=(12,12), class_names=classes_names)
'Classes Name NOT Working'
plot_confusion_matrix(mat, figsize=(12,12))